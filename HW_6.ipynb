{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Задача №9\n",
    "Часто предобработка текста перед подачей его алгоритмам машинного обучения состоит в следующем: текст токенизируют, чистят от пунктуации, чистят от стоп-слов, нормализуют и лемматизируют токены, заменяют токены числами (так, чтобы по числу было можно восстановить токен), делают паддинг -- дополняют список токенов до заранее оговорённой длины, добавляя какое-то количество нулей в конец списка.\n",
    "\n",
    "Сочините код, написанный с исопльзованием функций который был бы рыбой для такой предобработки: каждый этап предобработки замените либо максимально простой реализацией. ниже некоторые комментарии об этом\n",
    "\n",
    "лемматизацию/нормализацию реализуйте так, что лемматизатор отдаёт то же, что получил, но печатает \"todo: реализовать лемматизацию/нормализацию\".\n",
    "стоп-слова и пунктуацию можно определить в коде как какие-то простые списки. например, ['в', 'на', 'и'] и \",.?!\" будет вполне достаточно.\n",
    "заменять токены числами можно любым правилом, которое ставит строке в соответствие целое число. во время работы этого кода стоит печатать \"todo: реализовать правильную логику замены токенов числами\".\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"\"\"Часто предобработка текста перед подачей его алгоритмам машинного обучения состоит в следующем: текст токенизируют, чистят от пунктуации, чистят от стоп-слов, нормализуют и лемматизируют токены, заменяют токены числами (так, чтобы по числу было можно восстановить токен), делают паддинг -- дополняют список токенов до заранее оговорённой длины, добавляя какое-то количество нулей в конец списка.\n",
    "\n",
    "Сочините код, написанный с исопльзованием функций который был бы рыбой для такой предобработки: каждый этап предобработки замените либо максимально простой реализацией. ниже некоторые комментарии об этом\n",
    "\n",
    "лемматизацию/нормализацию реализуйте так, что лемматизатор отдаёт то же, что получил, но печатает \"todo: реализовать лемматизацию/нормализацию\".\n",
    "стоп-слова и пунктуацию можно определить в коде как какие-то простые списки. например, ['в', 'на', 'и'] и \",.?!\" будет вполне достаточно.\n",
    "заменять токены числами можно любым правилом, которое ставит строке в соответствие целое число. во время работы этого кода стоит печатать \"todo: реализовать правильную логику замены токенов числами\".\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(text):\n",
    "    tokens = text.lower().replace(\"/\", \" / \").split()\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['часто',\n",
       " 'предобработка',\n",
       " 'текста',\n",
       " 'перед',\n",
       " 'подачей',\n",
       " 'его',\n",
       " 'алгоритмам',\n",
       " 'машинного',\n",
       " 'обучения',\n",
       " 'состоит',\n",
       " 'в',\n",
       " 'следующем:',\n",
       " 'текст',\n",
       " 'токенизируют,',\n",
       " 'чистят',\n",
       " 'от',\n",
       " 'пунктуации,',\n",
       " 'чистят',\n",
       " 'от',\n",
       " 'стоп-слов,',\n",
       " 'нормализуют',\n",
       " 'и',\n",
       " 'лемматизируют',\n",
       " 'токены,',\n",
       " 'заменяют',\n",
       " 'токены',\n",
       " 'числами',\n",
       " '(так,',\n",
       " 'чтобы',\n",
       " 'по',\n",
       " 'числу',\n",
       " 'было',\n",
       " 'можно',\n",
       " 'восстановить',\n",
       " 'токен),',\n",
       " 'делают',\n",
       " 'паддинг',\n",
       " '--',\n",
       " 'дополняют',\n",
       " 'список',\n",
       " 'токенов',\n",
       " 'до',\n",
       " 'заранее',\n",
       " 'оговорённой',\n",
       " 'длины,',\n",
       " 'добавляя',\n",
       " 'какое-то',\n",
       " 'количество',\n",
       " 'нулей',\n",
       " 'в',\n",
       " 'конец',\n",
       " 'списка.',\n",
       " 'сочините',\n",
       " 'код,',\n",
       " 'написанный',\n",
       " 'с',\n",
       " 'исопльзованием',\n",
       " 'функций',\n",
       " 'который',\n",
       " 'был',\n",
       " 'бы',\n",
       " 'рыбой',\n",
       " 'для',\n",
       " 'такой',\n",
       " 'предобработки:',\n",
       " 'каждый',\n",
       " 'этап',\n",
       " 'предобработки',\n",
       " 'замените',\n",
       " 'либо',\n",
       " 'максимально',\n",
       " 'простой',\n",
       " 'реализацией.',\n",
       " 'ниже',\n",
       " 'некоторые',\n",
       " 'комментарии',\n",
       " 'об',\n",
       " 'этом',\n",
       " 'лемматизацию',\n",
       " '/',\n",
       " 'нормализацию',\n",
       " 'реализуйте',\n",
       " 'так,',\n",
       " 'что',\n",
       " 'лемматизатор',\n",
       " 'отдаёт',\n",
       " 'то',\n",
       " 'же,',\n",
       " 'что',\n",
       " 'получил,',\n",
       " 'но',\n",
       " 'печатает',\n",
       " '\"todo:',\n",
       " 'реализовать',\n",
       " 'лемматизацию',\n",
       " '/',\n",
       " 'нормализацию\".',\n",
       " 'стоп-слова',\n",
       " 'и',\n",
       " 'пунктуацию',\n",
       " 'можно',\n",
       " 'определить',\n",
       " 'в',\n",
       " 'коде',\n",
       " 'как',\n",
       " 'какие-то',\n",
       " 'простые',\n",
       " 'списки.',\n",
       " 'например,',\n",
       " \"['в',\",\n",
       " \"'на',\",\n",
       " \"'и']\",\n",
       " 'и',\n",
       " '\",.?!\"',\n",
       " 'будет',\n",
       " 'вполне',\n",
       " 'достаточно.',\n",
       " 'заменять',\n",
       " 'токены',\n",
       " 'числами',\n",
       " 'можно',\n",
       " 'любым',\n",
       " 'правилом,',\n",
       " 'которое',\n",
       " 'ставит',\n",
       " 'строке',\n",
       " 'в',\n",
       " 'соответствие',\n",
       " 'целое',\n",
       " 'число.',\n",
       " 'во',\n",
       " 'время',\n",
       " 'работы',\n",
       " 'этого',\n",
       " 'кода',\n",
       " 'стоит',\n",
       " 'печатать',\n",
       " '\"todo:',\n",
       " 'реализовать',\n",
       " 'правильную',\n",
       " 'логику',\n",
       " 'замены',\n",
       " 'токенов',\n",
       " 'числами\".']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clear_punct(tokens):\n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        stripped_token = token.strip(punctuation)\n",
    "        if stripped_token:\n",
    "            cleaned_tokens.append(stripped_token)\n",
    "    return cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['часто',\n",
       " 'предобработка',\n",
       " 'текста',\n",
       " 'перед',\n",
       " 'подачей',\n",
       " 'его',\n",
       " 'алгоритмам',\n",
       " 'машинного',\n",
       " 'обучения',\n",
       " 'состоит',\n",
       " 'в',\n",
       " 'следующем',\n",
       " 'текст',\n",
       " 'токенизируют',\n",
       " 'чистят',\n",
       " 'от',\n",
       " 'пунктуации',\n",
       " 'чистят',\n",
       " 'от',\n",
       " 'стоп-слов',\n",
       " 'нормализуют',\n",
       " 'и',\n",
       " 'лемматизируют',\n",
       " 'токены',\n",
       " 'заменяют',\n",
       " 'токены',\n",
       " 'числами',\n",
       " 'так',\n",
       " 'чтобы',\n",
       " 'по',\n",
       " 'числу',\n",
       " 'было',\n",
       " 'можно',\n",
       " 'восстановить',\n",
       " 'токен',\n",
       " 'делают',\n",
       " 'паддинг',\n",
       " 'дополняют',\n",
       " 'список',\n",
       " 'токенов',\n",
       " 'до',\n",
       " 'заранее',\n",
       " 'оговорённой',\n",
       " 'длины',\n",
       " 'добавляя',\n",
       " 'какое-то',\n",
       " 'количество',\n",
       " 'нулей',\n",
       " 'в',\n",
       " 'конец',\n",
       " 'списка',\n",
       " 'сочините',\n",
       " 'код',\n",
       " 'написанный',\n",
       " 'с',\n",
       " 'исопльзованием',\n",
       " 'функций',\n",
       " 'который',\n",
       " 'был',\n",
       " 'бы',\n",
       " 'рыбой',\n",
       " 'для',\n",
       " 'такой',\n",
       " 'предобработки',\n",
       " 'каждый',\n",
       " 'этап',\n",
       " 'предобработки',\n",
       " 'замените',\n",
       " 'либо',\n",
       " 'максимально',\n",
       " 'простой',\n",
       " 'реализацией',\n",
       " 'ниже',\n",
       " 'некоторые',\n",
       " 'комментарии',\n",
       " 'об',\n",
       " 'этом',\n",
       " 'лемматизацию',\n",
       " 'нормализацию',\n",
       " 'реализуйте',\n",
       " 'так',\n",
       " 'что',\n",
       " 'лемматизатор',\n",
       " 'отдаёт',\n",
       " 'то',\n",
       " 'же',\n",
       " 'что',\n",
       " 'получил',\n",
       " 'но',\n",
       " 'печатает',\n",
       " 'todo',\n",
       " 'реализовать',\n",
       " 'лемматизацию',\n",
       " 'нормализацию',\n",
       " 'стоп-слова',\n",
       " 'и',\n",
       " 'пунктуацию',\n",
       " 'можно',\n",
       " 'определить',\n",
       " 'в',\n",
       " 'коде',\n",
       " 'как',\n",
       " 'какие-то',\n",
       " 'простые',\n",
       " 'списки',\n",
       " 'например',\n",
       " 'в',\n",
       " 'на',\n",
       " 'и',\n",
       " 'и',\n",
       " 'будет',\n",
       " 'вполне',\n",
       " 'достаточно',\n",
       " 'заменять',\n",
       " 'токены',\n",
       " 'числами',\n",
       " 'можно',\n",
       " 'любым',\n",
       " 'правилом',\n",
       " 'которое',\n",
       " 'ставит',\n",
       " 'строке',\n",
       " 'в',\n",
       " 'соответствие',\n",
       " 'целое',\n",
       " 'число',\n",
       " 'во',\n",
       " 'время',\n",
       " 'работы',\n",
       " 'этого',\n",
       " 'кода',\n",
       " 'стоит',\n",
       " 'печатать',\n",
       " 'todo',\n",
       " 'реализовать',\n",
       " 'правильную',\n",
       " 'логику',\n",
       " 'замены',\n",
       " 'токенов',\n",
       " 'числами']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clear_punct(tokenize(text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('russian')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def delete_stop_words(tokens):\n",
    "    new_tokens = []\n",
    "    for token in tokens:\n",
    "        if token not in stop_words:\n",
    "            new_tokens.append(token)\n",
    "    return new_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['часто',\n",
       " 'предобработка',\n",
       " 'текста',\n",
       " 'подачей',\n",
       " 'алгоритмам',\n",
       " 'машинного',\n",
       " 'обучения',\n",
       " 'состоит',\n",
       " 'следующем',\n",
       " 'текст',\n",
       " 'токенизируют',\n",
       " 'чистят',\n",
       " 'пунктуации',\n",
       " 'чистят',\n",
       " 'стоп-слов',\n",
       " 'нормализуют',\n",
       " 'лемматизируют',\n",
       " 'токены',\n",
       " 'заменяют',\n",
       " 'токены',\n",
       " 'числами',\n",
       " 'числу',\n",
       " 'восстановить',\n",
       " 'токен',\n",
       " 'делают',\n",
       " 'паддинг',\n",
       " 'дополняют',\n",
       " 'список',\n",
       " 'токенов',\n",
       " 'заранее',\n",
       " 'оговорённой',\n",
       " 'длины',\n",
       " 'добавляя',\n",
       " 'какое-то',\n",
       " 'количество',\n",
       " 'нулей',\n",
       " 'конец',\n",
       " 'списка',\n",
       " 'сочините',\n",
       " 'код',\n",
       " 'написанный',\n",
       " 'исопльзованием',\n",
       " 'функций',\n",
       " 'который',\n",
       " 'рыбой',\n",
       " 'предобработки',\n",
       " 'каждый',\n",
       " 'этап',\n",
       " 'предобработки',\n",
       " 'замените',\n",
       " 'либо',\n",
       " 'максимально',\n",
       " 'простой',\n",
       " 'реализацией',\n",
       " 'ниже',\n",
       " 'некоторые',\n",
       " 'комментарии',\n",
       " 'лемматизацию',\n",
       " 'нормализацию',\n",
       " 'реализуйте',\n",
       " 'лемматизатор',\n",
       " 'отдаёт',\n",
       " 'получил',\n",
       " 'печатает',\n",
       " 'todo',\n",
       " 'реализовать',\n",
       " 'лемматизацию',\n",
       " 'нормализацию',\n",
       " 'стоп-слова',\n",
       " 'пунктуацию',\n",
       " 'определить',\n",
       " 'коде',\n",
       " 'какие-то',\n",
       " 'простые',\n",
       " 'списки',\n",
       " 'например',\n",
       " 'вполне',\n",
       " 'достаточно',\n",
       " 'заменять',\n",
       " 'токены',\n",
       " 'числами',\n",
       " 'любым',\n",
       " 'правилом',\n",
       " 'которое',\n",
       " 'ставит',\n",
       " 'строке',\n",
       " 'соответствие',\n",
       " 'целое',\n",
       " 'число',\n",
       " 'время',\n",
       " 'работы',\n",
       " 'кода',\n",
       " 'стоит',\n",
       " 'печатать',\n",
       " 'todo',\n",
       " 'реализовать',\n",
       " 'правильную',\n",
       " 'логику',\n",
       " 'замены',\n",
       " 'токенов',\n",
       " 'числами']"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delete_stop_words(clear_punct(tokenize(text)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize(tokens):\n",
    "    print(\"todo: реализовать лемматизацию/нормализацию\")\n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "todo: реализовать лемматизацию/нормализацию\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['часто',\n",
       " 'предобработка',\n",
       " 'текста',\n",
       " 'подачей',\n",
       " 'алгоритмам',\n",
       " 'машинного',\n",
       " 'обучения',\n",
       " 'состоит',\n",
       " 'следующем',\n",
       " 'текст',\n",
       " 'токенизируют',\n",
       " 'чистят',\n",
       " 'пунктуации',\n",
       " 'чистят',\n",
       " 'стоп-слов',\n",
       " 'нормализуют',\n",
       " 'лемматизируют',\n",
       " 'токены',\n",
       " 'заменяют',\n",
       " 'токены',\n",
       " 'числами',\n",
       " 'числу',\n",
       " 'восстановить',\n",
       " 'токен',\n",
       " 'делают',\n",
       " 'паддинг',\n",
       " 'дополняют',\n",
       " 'список',\n",
       " 'токенов',\n",
       " 'заранее',\n",
       " 'оговорённой',\n",
       " 'длины',\n",
       " 'добавляя',\n",
       " 'какое-то',\n",
       " 'количество',\n",
       " 'нулей',\n",
       " 'конец',\n",
       " 'списка',\n",
       " 'сочините',\n",
       " 'код',\n",
       " 'написанный',\n",
       " 'исопльзованием',\n",
       " 'функций',\n",
       " 'который',\n",
       " 'рыбой',\n",
       " 'предобработки',\n",
       " 'каждый',\n",
       " 'этап',\n",
       " 'предобработки',\n",
       " 'замените',\n",
       " 'либо',\n",
       " 'максимально',\n",
       " 'простой',\n",
       " 'реализацией',\n",
       " 'ниже',\n",
       " 'некоторые',\n",
       " 'комментарии',\n",
       " 'лемматизацию',\n",
       " 'нормализацию',\n",
       " 'реализуйте',\n",
       " 'лемматизатор',\n",
       " 'отдаёт',\n",
       " 'получил',\n",
       " 'печатает',\n",
       " 'todo',\n",
       " 'реализовать',\n",
       " 'лемматизацию',\n",
       " 'нормализацию',\n",
       " 'стоп-слова',\n",
       " 'пунктуацию',\n",
       " 'определить',\n",
       " 'коде',\n",
       " 'какие-то',\n",
       " 'простые',\n",
       " 'списки',\n",
       " 'например',\n",
       " 'вполне',\n",
       " 'достаточно',\n",
       " 'заменять',\n",
       " 'токены',\n",
       " 'числами',\n",
       " 'любым',\n",
       " 'правилом',\n",
       " 'которое',\n",
       " 'ставит',\n",
       " 'строке',\n",
       " 'соответствие',\n",
       " 'целое',\n",
       " 'число',\n",
       " 'время',\n",
       " 'работы',\n",
       " 'кода',\n",
       " 'стоит',\n",
       " 'печатать',\n",
       " 'todo',\n",
       " 'реализовать',\n",
       " 'правильную',\n",
       " 'логику',\n",
       " 'замены',\n",
       " 'токенов',\n",
       " 'числами']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatize(delete_stop_words(clear_punct(tokenize(text))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dict(tokens):\n",
    "    cur_dict = []\n",
    "    for token in tokens:\n",
    "        if token not in cur_dict:\n",
    "            cur_dict.append(token)\n",
    "    return cur_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "todo: реализовать лемматизацию/нормализацию\n"
     ]
    }
   ],
   "source": [
    "text_tokens = lemmatize(delete_stop_words(clear_punct(tokenize(text))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "mydict = create_dict(text_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_ids = []\n",
    "\n",
    "for token in text_tokens:\n",
    "    text_ids.append(mydict.index(token))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 часто\n",
      "1 предобработка\n",
      "2 текста\n",
      "3 подачей\n",
      "4 алгоритмам\n",
      "5 машинного\n",
      "6 обучения\n",
      "7 состоит\n",
      "8 следующем\n",
      "9 текст\n",
      "10 токенизируют\n",
      "11 чистят\n",
      "12 пунктуации\n",
      "11 чистят\n",
      "13 стоп-слов\n",
      "14 нормализуют\n",
      "15 лемматизируют\n",
      "16 токены\n",
      "17 заменяют\n",
      "16 токены\n",
      "18 числами\n",
      "19 числу\n",
      "20 восстановить\n",
      "21 токен\n",
      "22 делают\n",
      "23 паддинг\n",
      "24 дополняют\n",
      "25 список\n",
      "26 токенов\n",
      "27 заранее\n",
      "28 оговорённой\n",
      "29 длины\n",
      "30 добавляя\n",
      "31 какое-то\n",
      "32 количество\n",
      "33 нулей\n",
      "34 конец\n",
      "35 списка\n",
      "36 сочините\n",
      "37 код\n",
      "38 написанный\n",
      "39 исопльзованием\n",
      "40 функций\n",
      "41 который\n",
      "42 рыбой\n",
      "43 предобработки\n",
      "44 каждый\n",
      "45 этап\n",
      "43 предобработки\n",
      "46 замените\n",
      "47 либо\n",
      "48 максимально\n",
      "49 простой\n",
      "50 реализацией\n",
      "51 ниже\n",
      "52 некоторые\n",
      "53 комментарии\n",
      "54 лемматизацию\n",
      "55 нормализацию\n",
      "56 реализуйте\n",
      "57 лемматизатор\n",
      "58 отдаёт\n",
      "59 получил\n",
      "60 печатает\n",
      "61 todo\n",
      "62 реализовать\n",
      "54 лемматизацию\n",
      "55 нормализацию\n",
      "63 стоп-слова\n",
      "64 пунктуацию\n",
      "65 определить\n",
      "66 коде\n",
      "67 какие-то\n",
      "68 простые\n",
      "69 списки\n",
      "70 например\n",
      "71 вполне\n",
      "72 достаточно\n",
      "73 заменять\n",
      "16 токены\n",
      "18 числами\n",
      "74 любым\n",
      "75 правилом\n",
      "76 которое\n",
      "77 ставит\n",
      "78 строке\n",
      "79 соответствие\n",
      "80 целое\n",
      "81 число\n",
      "82 время\n",
      "83 работы\n",
      "84 кода\n",
      "85 стоит\n",
      "86 печатать\n",
      "61 todo\n",
      "62 реализовать\n",
      "87 правильную\n",
      "88 логику\n",
      "89 замены\n",
      "26 токенов\n",
      "18 числами\n"
     ]
    }
   ],
   "source": [
    "for i in text_ids:\n",
    "    print(i, mydict[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = text.split(\"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Часто предобработка текста перед подачей его алгоритмам машинного обучения состоит в следующем: текст токенизируют, чистят от пунктуации, чистят от стоп-слов, нормализуют и лемматизируют токены, заменяют токены числами (так, чтобы по числу было можно восстановить токен), делают паддинг -- дополняют список токенов до заранее оговорённой длины, добавляя какое-то количество нулей в конец списка.',\n",
       " 'Сочините код, написанный с исопльзованием функций который был бы рыбой для такой предобработки: каждый этап предобработки замените либо максимально простой реализацией. ниже некоторые комментарии об этом',\n",
       " 'лемматизацию/нормализацию реализуйте так, что лемматизатор отдаёт то же, что получил, но печатает \"todo: реализовать лемматизацию/нормализацию\".\\nстоп-слова и пунктуацию можно определить в коде как какие-то простые списки. например, [\\'в\\', \\'на\\', \\'и\\'] и \",.?!\" будет вполне достаточно.\\nзаменять токены числами можно любым правилом, которое ставит строке в соответствие целое число. во время работы этого кода стоит печатать \"todo: реализовать правильную логику замены токенов числами\".']"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    return lemmatize(delete_stop_words(clear_punct(tokenize(text))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "commondict = [\"<PAD>\"]\n",
    "\n",
    "def tokens2ids(tokens):\n",
    "    ids = []\n",
    "    for token in tokens:\n",
    "        if token not in commondict:\n",
    "            ids.append(len(commondict))\n",
    "            commondict.append(token)\n",
    "        else:\n",
    "            ids.append(commondict.index(token))\n",
    "    return ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "todo: реализовать лемматизацию/нормализацию\n",
      "['часто', 'предобработка', 'текста', 'подачей', 'алгоритмам', 'машинного', 'обучения', 'состоит', 'следующем', 'текст', 'токенизируют', 'чистят', 'пунктуации', 'чистят', 'стоп-слов', 'нормализуют', 'лемматизируют', 'токены', 'заменяют', 'токены', 'числами', 'числу', 'восстановить', 'токен', 'делают', 'паддинг', 'дополняют', 'список', 'токенов', 'заранее', 'оговорённой', 'длины', 'добавляя', 'какое-то', 'количество', 'нулей', 'конец', 'списка'] [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 12, 14, 15, 16, 17, 18, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36] 38\n",
      "todo: реализовать лемматизацию/нормализацию\n",
      "['сочините', 'код', 'написанный', 'исопльзованием', 'функций', 'который', 'рыбой', 'предобработки', 'каждый', 'этап', 'предобработки', 'замените', 'либо', 'максимально', 'простой', 'реализацией', 'ниже', 'некоторые', 'комментарии'] [37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 44, 47, 48, 49, 50, 51, 52, 53, 54] 19\n",
      "todo: реализовать лемматизацию/нормализацию\n",
      "['лемматизацию', 'нормализацию', 'реализуйте', 'лемматизатор', 'отдаёт', 'получил', 'печатает', 'todo', 'реализовать', 'лемматизацию', 'нормализацию', 'стоп-слова', 'пунктуацию', 'определить', 'коде', 'какие-то', 'простые', 'списки', 'например', 'вполне', 'достаточно', 'заменять', 'токены', 'числами', 'любым', 'правилом', 'которое', 'ставит', 'строке', 'соответствие', 'целое', 'число', 'время', 'работы', 'кода', 'стоит', 'печатать', 'todo', 'реализовать', 'правильную', 'логику', 'замены', 'токенов', 'числами'] [55, 56, 57, 58, 59, 60, 61, 62, 63, 55, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 17, 19, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 62, 63, 88, 89, 90, 27, 19] 44\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    tokens = preprocess(sentence)\n",
    "    ids = tokens2ids(tokens)\n",
    "    print(tokens, ids, len(ids))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "commondict == mydict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pad_sequences(sequence, seqlen):\n",
    "    return sequence + [0]*(seqlen-len(sequence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "todo: реализовать лемматизацию/нормализацию\n",
      "['часто', 'предобработка', 'текста', 'подачей', 'алгоритмам', 'машинного', 'обучения', 'состоит', 'следующем', 'текст', 'токенизируют', 'чистят', 'пунктуации', 'чистят', 'стоп-слов', 'нормализуют', 'лемматизируют', 'токены', 'заменяют', 'токены', 'числами', 'числу', 'восстановить', 'токен', 'делают', 'паддинг', 'дополняют', 'список', 'токенов', 'заранее', 'оговорённой', 'длины', 'добавляя', 'какое-то', 'количество', 'нулей', 'конец', 'списка']\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 12, 14, 15, 16, 17, 18, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36]\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 12, 14, 15, 16, 17, 18, 17, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "**********\n",
      "todo: реализовать лемматизацию/нормализацию\n",
      "['сочините', 'код', 'написанный', 'исопльзованием', 'функций', 'который', 'рыбой', 'предобработки', 'каждый', 'этап', 'предобработки', 'замените', 'либо', 'максимально', 'простой', 'реализацией', 'ниже', 'некоторые', 'комментарии']\n",
      "[37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 44, 47, 48, 49, 50, 51, 52, 53, 54]\n",
      "[37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 44, 47, 48, 49, 50, 51, 52, 53, 54, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "**********\n",
      "todo: реализовать лемматизацию/нормализацию\n",
      "['лемматизацию', 'нормализацию', 'реализуйте', 'лемматизатор', 'отдаёт', 'получил', 'печатает', 'todo', 'реализовать', 'лемматизацию', 'нормализацию', 'стоп-слова', 'пунктуацию', 'определить', 'коде', 'какие-то', 'простые', 'списки', 'например', 'вполне', 'достаточно', 'заменять', 'токены', 'числами', 'любым', 'правилом', 'которое', 'ставит', 'строке', 'соответствие', 'целое', 'число', 'время', 'работы', 'кода', 'стоит', 'печатать', 'todo', 'реализовать', 'правильную', 'логику', 'замены', 'токенов', 'числами']\n",
      "[55, 56, 57, 58, 59, 60, 61, 62, 63, 55, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 17, 19, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 62, 63, 88, 89, 90, 27, 19]\n",
      "[55, 56, 57, 58, 59, 60, 61, 62, 63, 55, 56, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 17, 19, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 62, 63, 88, 89, 90, 27, 19, 0, 0, 0, 0, 0, 0]\n",
      "**********\n"
     ]
    }
   ],
   "source": [
    "for sentence in sentences:\n",
    "    tokens = preprocess(sentence)\n",
    "    ids = tokens2ids(tokens)\n",
    "    padded_ids = pad_sequences(ids, 50)\n",
    "    print(tokens)\n",
    "    print(ids)\n",
    "    print(padded_ids)\n",
    "    print(\"*\"*10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = []\n",
    "\n",
    "def some_fn(number):\n",
    "    a.append(number**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "some_fn(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Задача №7\n",
    "Напишите код, который будет проверять, есть ли в файле с кодом такие описанные программистом функции, в теле которых вызываются описанные в том же файле функции.\n",
    "Если одна функция вызывает другую, и вызываемая при этом описана ниже вызывающей, стоит напечатать сообщение \"неправильно упорядочены функции\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Введите имя файла: aaa.txt\n"
     ]
    }
   ],
   "source": [
    "file_to_check_name = input('Введите имя файла: ')\n",
    "\n",
    "def get_names_and_bodies(filename):\n",
    "    names_of_functions = []\n",
    "    bodies = []\n",
    "\n",
    "    with open(filename, 'r', encoding='utf-8') as f:\n",
    "        cur_body = \"\"\n",
    "        for line in f:\n",
    "            if line.startswith('def ') and line.endswith('):\\n'):\n",
    "                if cur_body:\n",
    "                    bodies.append(cur_body)\n",
    "                    cur_body = \"\"\n",
    "                name = line.split(\"(\")[0][4:]\n",
    "                names_of_functions.append(name)\n",
    "            else:\n",
    "                if line.startswith(\"    \"):\n",
    "                    cur_body += line\n",
    "        bodies.append(cur_body)\n",
    "    \n",
    "    return names_of_functions, bodies\n",
    "\n",
    "names, bodies = get_names_and_bodies(file_to_check_name)\n",
    "\n",
    "for i, name in enumerate(names):\n",
    "    for body in bodies[:i]:\n",
    "        if name in body:\n",
    "            print(\"неправильно упорядочены функции\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "names, bodies = get_names_and_bodies(file_to_check_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['write_file', 'read_file']"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    result = []\n",
      "    with open(filename, 'r', encoding=\"utf-8\") as f:\n",
      "        for line in f:\n",
      "            result.append(line)\n",
      "    rlt = result, read_file(filename)\n",
      "    return rlt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bodies[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    result = []\n",
      "    with open(fename, 'r', encoding=\"utf-8\") as f:\n",
      "        for line in f:\n",
      "            result.append(read_file)\n",
      "    return result\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(bodies[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_name(name):\n",
    "    alphabet = \"_abcdefghijklmnopqrstuvwxyz0123456789\"\n",
    "    nums = \"0123456789\"\n",
    "    if name[0] in nums:\n",
    "        return False\n",
    "    for i in name:\n",
    "        if i.lower() not in alphabet:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_funcdef_line(line):\n",
    "    line = line.strip()\n",
    "    if line.startswith(\"def \") and line.endswith(\"):\"):\n",
    "        shortline = line[4:-2]\n",
    "        if \"(\" in shortline:\n",
    "            name, args = shortline.strip().split(\"(\")\n",
    "            args = args.split(\",\")\n",
    "            if check_name(name) and all([check_name(arg.strip()) for arg in args if arg]):\n",
    "                return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [i*10 for i in range(10)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all([True, True])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
